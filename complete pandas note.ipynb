{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"complete pandas note.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNvCDeB50uJbvuWU7By71au"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HibjRfU26FtH"},"source":["**. Data import with Pandas\n","Pandas input output API provides several functions that can be used to import and export various file formats.\n","\n","Below is the list of file formats and the corresponding functions to import these file formats.\n","\n","Flat files - read_csv(), to_csv()\n","\n","Excel files - read_excel(), ExcelWriter(), to_excel()\n","\n","JSON files - read_json(), to_json()\n","\n","HTML tables - read_html(), to_html()\n","\n","SAS files - read_sas()\n","\n","SQL files - read_sql(), read_sql_query(), read_sql_table(), to_sql()\n","\n","STATA files - read_stata(), to_stata()\n","\n","pickle object - read_pickle(), to_pickle()\n","\n","HDF5 files - read_hdf(), to_hdf()**"]},{"cell_type":"code","metadata":{"id":"kmJvf-tDt1w9"},"source":["import pandas as pd\n","import numpy as np \n","import seaborn as sns\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFsKx4ZLt60-"},"source":["# initialize data of lists.\n","data = {'Name':['Vamshi','Sairam','Madhan','Rahul','Ashok','Ravi','Praveen'],\n","        'Age_Sex':['20_M', '21_M', '25_M', '30_M','45_M','32_M','200_M'],\n","        'height(cm)':[160,-175.5,140.7,0.0,np.NaN,162.4,165],\n","        'Weight(kg)':[80, 67, np.NaN, 62.5, 66.4, np.NaN, 73],\n","        'Spend_A':[2000,3000,5000,7000,np.NaN,-2000, np.NaN],\n","        'Spend_B':[200, 500, 1500, 1700, 2000, np.NaN,750],\n","        }\n","  \n","# Create DataFrame\n","df = pd.DataFrame(data)\n","  \n","# Print the output.\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KjG1BISXfrBv"},"source":["data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4yMatg_UfHEz"},"source":["**Exploratory data analysis**"]},{"cell_type":"markdown","metadata":{"id":"spzA5lv-feWq"},"source":["**check the type of df**\n","\n","I have imported the dataset. The next step is to check its type. We can check its type with the following command:-**"]},{"cell_type":"code","metadata":{"id":"KZwW69OQe9-Q"},"source":["type(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tm6K1obSfXVz"},"source":["df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8vBdVI9fsE_"},"source":["\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zZYkPaPNUPeM"},"source":["df['Weight(kg)'].sort_values()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2amoYh-Gfutu","colab":{"base_uri":"https://localhost:8080/","height":166},"executionInfo":{"status":"error","timestamp":1638448314865,"user_tz":-330,"elapsed":24,"user":{"displayName":"Thota Vamshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj2FPcpoxsghcdfB474ktIwaCaejRZOSbFUdGLK5Q=s64","userId":"05568049229341690928"}},"outputId":"7ce8b1a3-68b7-4b17-9c02-78c9cceb65d9"},"source":["df.info()"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a74c58233b9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]},{"cell_type":"code","metadata":{"id":"MlCDZF3AfzvP"},"source":["df.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kF_MbjBvgzjZ"},"source":["df.isna().sum()\n","\n","detect ‘NA’ values in a particular column in the dataframe\n","\n","pd.isna(df[‘col_name’])\n","\n","df[‘col_name’].notna()"]},{"cell_type":"code","metadata":{"id":"DdvZmyuIP_Wb"},"source":["df['height(cm)'].notna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5VpPp4M0f0zP"},"source":["df.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H4WDnmW2hCpN"},"source":["Encode missing numerical values\n","\n","\n","Missing values are encoded in different ways. \n","\n","They can appear as NaN, NA, ?, zeros, xx, -1 or a blank space “ ”. We can use various pandas methods to deal with missing values.\n","\n","But, pandas always recognize missing values as NaN. So, \n","\n","it is essential that we should first convert all the ?, zeros, xx, -1 or “ ” to NaN. \n","\n","If the missing values isn’t identified as NaN, then we have to first convert or replace such non NaN entry with a NaN."]},{"cell_type":"code","metadata":{"id":"90UdzptTg483"},"source":["#Convert '?' to ‘NaN’\n","df[df == '?'] = np.nan"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_XZRpckdhR6h"},"source":["Handle missing numerical values\n"]},{"cell_type":"markdown","metadata":{"id":"vJz8tEVQhXsv"},"source":["Drop missing values with dropna() method\n","\n","Fill missing values with zeros\n","\n","Fill missing values backward or forward"]},{"cell_type":"markdown","metadata":{"id":"tRgbZMYkhqkr"},"source":["The pad or fill option fill values forward, while bfill or backfill option fill values backward.\n","\n"]},{"cell_type":"code","metadata":{"id":"dYsY8jrb7GES"},"source":["df.columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Ea-2Gtig45v"},"source":["df[['Name', 'Weight(kg)']].head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QMWqcq7fiDzW"},"source":["sometimes we can see that the first element of each column are NaN. \n","\n","So, in this case pad or fill option does not work. Here, we should use bfill or backfill options as follows:-"]},{"cell_type":"code","metadata":{"id":"KzI3IBHQh_7l"},"source":["df = df.fillna(method = 'backfill')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kNpLE8ZNiQcI"},"source":["Check with ASSERT statement\n","Asserts\n","\n","Check with ASSERT statement\n","Finally, we should check for missing values programmatically. \n","\n","\n","If we drop or fill missing values, we expect no missing values. We can write an assert statement to verify this. So, \n","\n","we can use an assert statement to programmatically check that no missing or unexpected '0' value is present. This gives confidence that our code is running properly.\n","\n","Assert statement will return nothing if the value being tested is true and will throw an AssertionError if the value is false.\n","\n","\n","\n","• assert 1 == 1 (return Nothing if the value is True)\n","\n","• assert 1 == 2 (return AssertionError if the value is False)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QJ8azNQgie7P"},"source":["Indexing and slicing in pandas\n"]},{"cell_type":"markdown","metadata":{"id":"h6IquEmZitPO"},"source":[".loc - Label based\n","\n","\n",".iloc - Integer based\n","\n","\n",".ix - Both Label and Integer based"]},{"cell_type":"code","metadata":{"id":"UODsR_Neh_4g"},"source":["# select first row of dataframe\n","df.loc[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0ZqvBBhh_1Z"},"source":["#select first five rows for a specific column\n","\n","df.loc[:,'Spend_A'].head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uG-xDQ4HjVrN"},"source":["Rows selection using .iloc indexer\n","Below are the examples of row selection using .iloc indexer\n","\n","select first row of dataframe\n","df1.iloc[0]\n","\n","select second row of dataframe\n","df1.iloc[1]\n","\n","select last row of dataframe\n","df1.iloc[-1]\n","\n","select second last row of dataframe\n","df1.iloc[-2]"]},{"cell_type":"code","metadata":{"id":"Zo1EdWgM1d9T"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h182YYUV8kKS"},"source":["# to select all columns except last column\n","df.iloc[:,:-2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cj6Mhj1r3Pwf"},"source":["df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ju45ze7U8uz3"},"source":["df.iloc[:,:-2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9YPd_gnm9T-N"},"source":["df.iloc[3]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_-_j13f7jgIO"},"source":["Multiple rows and columns selection using .iloc indexer\n","select first five rows of dataframe\n","df1.iloc[0:5]\n","\n","select first five columns of data frame with all rows\n","df1.loc[:, 0:5]\n","\n","select 1st, 5th and 10th rows with 1st, 4th and 7th columns\n","df1.iloc[[0,4,9]], [0,3,6]]\n","\n","select first 5 rows and 5th, 6th, 7th columns of data frame\n","df1.iloc[0:5, 5:8]"]},{"cell_type":"code","metadata":{"id":"HCP1-N789hCB"},"source":["df.iloc[[0,3,5], [0,3,4]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FD9KSno7j2Et"},"source":["Indexing first occurrence of maximum or minimum values with idxmax() and idxmin()\n","Pandas provide two functions idxmax() and idxmin() \n","\n","that return index of first occurrence of maximum or minimum values over requested axis. \n","\n","NA/null values are excluded from the output."]},{"cell_type":"code","metadata":{"id":"ELSjCcOPh_x7"},"source":["# get index of first occurence of maximum Weight(kg) value \n","\n","df['Weight(kg)'].idxmax()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gNrEWCZTg42W"},"source":["# get the row with the maximum Weight(kg) value \n","\n","df.loc[df['Weight(kg)'].idxmax()]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HUi6l6a8kPAC"},"source":["Indexing a single value with at() and iat()\n","\n","\n","Pandas provides at() and iat() functions to access a single value for a row and column pair by label or by integer position.\n","\n"]},{"cell_type":"code","metadata":{"id":"xfJOgFDiYKDt"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9AxELKo5j9cQ"},"source":["# get value at 1st row and Weight(kg) column pair\n","\n","df.at[1, 'Spend_A']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"So2VpnShj9Yq"},"source":["# get value at 1st row and 4th column pair\n","\n","df.iat[2, 3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SDJBtF4ej9Va"},"source":["# get the purchase amount with a given user_id and product_id\n","\n","df.loc[((df['Weight(kg)'] == 80.0) & (df['Name'] == 'Vamshi')), 'height(cm)']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJpbVRgDj9PN"},"source":["food = pd.DataFrame({'Place':['Home', 'Home', 'Hotel', 'Hotel'],\n","                   'Time': ['Lunch', 'Dinner', 'Lunch', 'Dinner'],\n","                   'Food':['Soup', 'Rice', 'Soup', 'Chapati'],\n","                   'Price($)':[10, 20, 30, 40]})\n","\n","food"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mrpvhVRkmOhP"},"source":["**Set an index\n","DataFrame has a set_index() method which takes a column name (for a regular Index) or a list of column names (for a MultiIndex).\n","\n","\n"," This method sets the dataframe index using existing columns.\n","\n","I will create a new, re-indexed DataFrame with set_index() method as follows:-**"]},{"cell_type":"code","metadata":{"id":"ciKP-zTej9Ls"},"source":["food_indexed1=food.set_index('Place')\n","\n","food_indexed1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FduDOD1Ij9IT"},"source":["food_indexed2=food.set_index(['Place', 'Time'])\n","\n","food_indexed2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IHceyCPdmgz5"},"source":["**Reset the index**"]},{"cell_type":"code","metadata":{"id":"3Q5aqXLGmfDp"},"source":["food_indexed2.reset_index()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AK4w5CPTm56k"},"source":["**Sorting in pandas\n","Pandas provides two kinds of sorting. They are:-\n","\n","Sorting by label\n","\n","Sorting by actual value**\n","\n","\n","\n","**Sorting by label\n","We can use the sort_index() method to sort the object by labels. DataFrame can be sorted by passing the axis arguments and the order of sorting. By default, sorting is done on row labels in ascending order.\n","\n","The following examples illustrate the idea of sorting by label.**"]},{"cell_type":"code","metadata":{"id":"5TGEkSXFDF29"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"obwvYBoome_9"},"source":["# sort the dataframe df by label\n","\n","df.sort_index()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MA757lqlme8g"},"source":["df.sort_values(['Age_Sex'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G_ry2YScnmsT"},"source":["**Sort by multiple columns\n","df2.sort_values(by=['Product_Category_1', 'Product_Category_2'])\n","\n","Sort in descending order\n","df2.sort_values(by='Product_Category_1', ascending=False)** "]},{"cell_type":"markdown","metadata":{"id":"wfF3iBrzn7dS"},"source":["**Description of categorical data**"]},{"cell_type":"code","metadata":{"id":"1FkaT2RiiyMS"},"source":["df.describe(include='object').T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UGq9cjSXoSCD"},"source":["df['height(cm)'].describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0bYCL1Hro724"},"source":["\n","\n","*   List iteDataframe basic functionality\n","The following tables lists the important attributes or methods in Dataframe basic functionality.\n","\n","T - Transposes rows and columns.\n","\n","axes - Returns a list with the row axis labels and column axis labels as the only members.\n","\n","\n","dtypes - Returns the dtypes in this object.\n","\n","\n","empty - True if NDFrame is entirely empty [no items]; if any of the axes are of length 0.\n","\n","\n","ndim - Number of axes / array dimensions.\n","\n","\n","shape - Returns a tuple representing the dimensionality of the Dataframe.\n","\n","\n","size - Number of elements in the NDFrame.\n","\n","\n","values - Numpy representation of NDFrame.\n","\n","\n","head() - Returns the first n rows.\n","\n","\n","tail() - Returns last n rows.m\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"e2AAcVykjhpx"},"source":["df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kGKwX9vbjkIT"},"source":["df.size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-KuP5Eloifj"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"riYfJ3Snhzmn"},"source":["df['height(cm)'].sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yF95vsPNh8fI"},"source":["df['height(cm)'].std()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Y7lcxv_h8bH"},"source":["df['height(cm)'].min()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0JF1ZSe0iGAZ"},"source":["df['height(cm)'].max()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f2RrrcqyiMPp"},"source":["df['height(cm)'].abs()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"adWNzB6fpZaF"},"source":["\n","\n","*   List item1 count() - Number of non-null observations\n","\n","\n","2 sum() - Sum of values\n","\n","\n","3 mean() - Mean of values\n","\n","\n","4 median() - Median of values\n","\n","\n","5 mode() - Mode of values\n","\n","\n","6 std() - Standard deviation of the values\n","\n","\n","7 min() - Minimum value\n","\n","\n","8 max() - Maximum value\n","\n","\n","9 abs() - Absolute value\n","\n","\n","10 prod() - Product of values\n","\n","\n","11 cumsum() - Cumulative sum\n","\n","\n","12 cumprod() - Cumulative product\n","*   \n","\n"]},{"cell_type":"code","metadata":{"id":"CUMJfMJsoR-z"},"source":["# view the covariance\n","\n","df.cov()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6V9x9AMdEpJq"},"source":["**Correlation\n","Correlation shows the linear relationship between any two array of values (series). \n","There are multiple methods to compute the correlation. These methods are listed below:-\n","\n","Method name Description\n","\n","pearson (default) - Standard correlation coefficient*\n","\n","\n","spearman - Spearman rank correlation coefficient\n"]},{"cell_type":"code","metadata":{"id":"LqeQwZA5oR72"},"source":["# view the correlation\n","\n","df.corr()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MfU5Fx-YqcMd"},"source":["**Data Ranking**"]},{"cell_type":"markdown","metadata":{"id":"WCdviQ5ZqQ89"},"source":["The rank() supports different tie-breaking methods, specified with the method parameter as follows:-\n","\n","average - average rank of tied group\n","\n","\n","min - lowest rank in the group\n","\n","\n","max - highest rank in the group\n","\n","\n","first - ranks assigned in the order they appear in the array**"]},{"cell_type":"code","metadata":{"id":"q2LalNbEDgj0"},"source":["df.rank(1).head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kqeju4V-qZkE"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7aD80nf8A3wy"},"source":["df['height(cm)'].count()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"afXL1xObBKxb"},"source":["df['height(cm)'].sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yKaLq9iSBQlF"},"source":["df['Weight(kg)'].var()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wsZh0GyrBxaY"},"source":["**If the skewness is between -0.5 and 0.5, the data are fairly symmetrical. \n","\n","If the skewness is between -1 and – 0.5 or between 0.5 and 1, the data are moderately skewed. \n","\n","If the skewness is less than -1 or greater than 1, the data are highly skewed.*"]},{"cell_type":"code","metadata":{"id":"On12Byx6BZAJ"},"source":["df['height(cm)'].skew()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HPGN84P2C6x9"},"source":["**It is actually the measure of outliers present in the distribution .\n","\n"," High kurtosis in a data set is an indicator that data has heavy tails or outliers. ... \n"," \n"," It means that the extreme values of the distribution are similar to that of a normal distribution characteristic.*\n","\n"," asymmetry and kurtosis between -2 and +2 "]},{"cell_type":"code","metadata":{"id":"9nQBEccvB75d"},"source":["df['height(cm)'].kurt()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hPTEerAhqp7m"},"source":["\n","\n","* count() - Number of non-null observations\n","\n","\n","sum() - Sum of values\n","\n","mean() - Mean of values\n","\n","\n","median() - Arithmetic median of values\n","\n","\n","min() - Minimum\n","\n","\n","max() - Maximum\n","\n","\n","std() - Standard deviation\n","\n","\n","var() - Variance\n","\n","\n","skew() - Skewness\n","\n","\n","kurt() - Kurtosis\n","\n","\n","quantile() - Quantile\n","\n","\n","apply() - Generic apply\n","\n","\n","cov() - Covariance\n","\n","\n","corr() - Correlation\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ml8j-UwwrOie"},"source":["**Aggregations in pandas**"]},{"cell_type":"code","metadata":{"id":"NyimEOL7_0sK"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZcst4uZrNuG"},"source":["df['height(cm)'].aggregate(np.sum)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uswlfFcHq77c"},"source":["df['height(cm)'].aggregate([np.sum, np.mean])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-UT4ZNtJre0S"},"source":["df[['height(cm)', 'Weight(kg)', 'Spend_A']].aggregate(np.mean)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8y_7SzorkGO"},"source":["df[['height(cm)', 'Weight(kg)', 'Spend_A']].aggregate([np.sum, np.mean])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HCETw9G7rnXQ"},"source":["df.aggregate({'height(cm)' : np.sum ,'Weight(kg)' : np.mean})\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gP9F805stBU3"},"source":["# let's create two dataframes\n","\n","batsmen = pd.DataFrame({\n","   'id':[1,2,3,4,5],\n","   'Name': ['Rohit', 'Dhawan', 'Virat', 'Dhoni', 'Kedar'],\n","   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n","\n","bowler = pd.DataFrame(\n","   {'id':[1,2,3,4,5],\n","   'Name': ['Kumar', 'Bumrah', 'Shami', 'Kuldeep', 'Chahal'],\n","   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n","\n","\n","print(batsmen)\n","\n","\n","print(bowler)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VzIMXzYEtOoi"},"source":["Merge using 'how' argument\n","The how argument to merge specifies how to determine which keys are to be included in the resulting table. If a key combination does not appear in either the left or the right tables, the values in the joined table will be NA.\n","\n","Here is a summary of the how options and their SQL equivalent names −\n","\n","Merge Method - SQL Equivalent - Description\n","\n","\n","left - LEFT OUTER JOIN - Use keys from left object\n","\n","\n","right - RIGHT OUTER JOIN - Use keys from right object\n","\n","\n","outer - FULL OUTER JOIN - Use union of keys\n","\n","\n","inner - INNER JOIN - Use intersection of keys"]},{"cell_type":"code","metadata":{"id":"mQFj9QAltYLY"},"source":["# left join\n","\n","pd.merge(batsmen, bowler, on='subject_id', how='left')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pp6Xp0rytcal"},"source":["# right join\n","\n","pd.merge(batsmen, bowler, on='subject_id', how='right')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXAS-4ybtcYD"},"source":["# outer join\n","\n","pd.merge(batsmen, bowler, on='subject_id', how='outer')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5PSKzriPu9L7"},"source":["**Pandas concatenation operation**"]},{"cell_type":"code","metadata":{"id":"ZRreE3VZtitE"},"source":["# let's create two dataframes\n","\n","batsmen = pd.DataFrame({\n","   'id':[1,2,3,4,5],\n","   'Name': ['Rohit', 'Dhawan', 'Virat', 'Dhoni', 'Kedar'],\n","   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n","\n","bowler = pd.DataFrame(\n","   {'id':[1,2,3,4,5],\n","   'Name': ['Kumar', 'Bumrah', 'Shami', 'Kuldeep', 'Chahal'],\n","   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n","\n","\n","print(batsmen)\n","\n","\n","print(bowler)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q78BoRsFtcUZ"},"source":["# concatenate the dataframes\n","\n","\n","team=[batsmen, bowler]\n","\n","pd.concat(team)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SUfMxPCKrzK9"},"source":["team"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0RvIGaHQtcRg"},"source":["# associate keys with the dataframes\n","\n","pd.concat(team, keys=['x', 'y'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ivx98MJtcON"},"source":["pd.concat(team, axis=0)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5xc2bVH5vhAf"},"source":["**Concatenating using append**"]},{"cell_type":"code","metadata":{"id":"rGRG6lK_shpx"},"source":["batsmen"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HSMeYKTttcLU"},"source":["batsmen.append(bowler)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZ8xTolJ9zGp"},"source":["bowler.append(batsmen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dkom4QMz6zAK"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KM5gvRQEwKIA"},"source":["**Reshaping by melt and pivot\n","Melt creates wide-to-long format dataframe**"]},{"cell_type":"code","metadata":{"id":"-g2EVVkt7iQq"},"source":["# Melt is nothing but Decreasing its widening data and increasing its length and pivot is the reverse for the melt function "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIJ5Varwvbpq"},"source":["pd.melt(frame=df, id_vars=['Name','height(cm)','Age_Sex','Weight(kg)'],\n","                    value_vars=['Spend_A','Spend_B'], var_name='expenditure', value_name='amount')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYhZ_Pj12WpJ"},"source":["**Reshaping by stacking and unstacking**"]},{"cell_type":"code","metadata":{"id":"DROlPE8dvbmg"},"source":["# reshaping the rows and columns\n","cols=pd.MultiIndex.from_tuples([('weight', 'kg'), ('weight', 'pounds')])\n","\n","df15=pd.DataFrame([[75,165], [60, 132]],\n","                 index=['husband', 'wife'],\n","                 columns=cols)\n","\n","df15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kzy92u-xvbi4"},"source":["df16=df15.stack()\n","\n","df16"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mrVE2vu52rcC"},"source":["**Unstacking\n","It is the inverse operation of stacking. It means \"pivot\" a level of the \n","\n","(possibly hierarchical) row index to the column axis, producing a reshaped\n","\n"," dataframe with a new inner-most level of column labels.**"]},{"cell_type":"code","metadata":{"id":"a-9e8tjL2m73","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1637753555665,"user_tz":-330,"elapsed":380,"user":{"displayName":"Thota Vamshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj2FPcpoxsghcdfB474ktIwaCaejRZOSbFUdGLK5Q=s64","userId":"05568049229341690928"}},"outputId":"d6bbe5ab-a26d-45e9-bb12-fa35f38d9a51"},"source":["df16.unstack()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"2\" halign=\"left\">weight</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>kg</th>\n","      <th>pounds</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>husband</th>\n","      <td>75</td>\n","      <td>165</td>\n","    </tr>\n","    <tr>\n","      <th>wife</th>\n","      <td>60</td>\n","      <td>132</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        weight       \n","            kg pounds\n","husband     75    165\n","wife        60    132"]},"metadata":{},"execution_count":100}]},{"cell_type":"markdown","metadata":{"id":"H8FTTcwS24_z"},"source":["**Options and customization with pandas**"]},{"cell_type":"markdown","metadata":{"id":"PNI8nR7d3A9o"},"source":["\n","\n","* The API is composed of five relevant functions. They are as follows :−\n","\n","get_option()\n","\n","\n","set_option()\n","\n","\n","reset_option()\n","\n","\n","describe_option()\n","\n","\n","option_context()\n","*  \n","\n"]},{"cell_type":"code","metadata":{"id":"jya3Hn7ykUAc"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mq6s4mKQ2m2d"},"source":["# display maximum rows\n","\n","pd.get_option(\"display.max_rows\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s2yY9_r42mr1"},"source":["pd.get_option(\"display.max_columns\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"41mZzAqr2mnM"},"source":["# set maximum rows\n","\n","pd.set_option(\"display.max_rows\", 80)\n","\n","pd.get_option(\"display.max_rows\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D4XhTYBx3UnP"},"source":["# set maximum columns\n","\n","pd.set_option(\"display.max_columns\", 30)\n","\n","pd.get_option(\"display.max_columns\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"miADDJ6p3UjS"},"source":["# reset_option() takes an argument and sets the value back to the default value.\n","\n","# display maximum rows\n","\n","pd.reset_option(\"display.max_rows\")\n","\n","pd.get_option(\"display.max_rows\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rFbkoySx3Ufw"},"source":["# display maximum columns\n","\n","pd.reset_option(\"display.max_columns\")\n","\n","pd.get_option(\"display.max_columns\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YGaTb2pKqud_"},"source":["**Pandas GroupBy operations\n","A groupby operation involves one of the following operations on the original object. They are as follows:−\n","\n","Splitting the Object\n","\n","Applying a function\n","\n","Combining the results**"]},{"cell_type":"markdown","metadata":{"id":"DzD2csVCrVcs"},"source":["**Aggregation − compute a summary statistic (or statistics) for each group. Some examples are:-\n","\n","Compute group sums or means.\n","\n","Compute group sizes / counts.\n","\n","\n","\n","Transformation − perform some group-specific computations and return a like-indexed object. Some examples are :-\n","\n","Standardize data (zscore) within a group.\n","\n","Filling NAs within groups with a value derived from each group.\n","\n","\n","\n","\n","Filtration − discarding the data with some condition. Some examples are :-\n","\n","Discard data that belongs to groups with only a few members.\n","\n","Filter out data based on the group sum or mean.**"]},{"cell_type":"code","metadata":{"id":"AY3u1Tos3UY5"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xtilm1yV3UVW"},"source":["df_grouped = df.groupby('Name')\n","\n","for Vamshi, Rahul in df_grouped:\n","  print (Rahul)\n","  print (Vamshi)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l-dDVpWytSPJ"},"source":["**Select a group\n","Using the get_group() method, we can select a single group.**"]},{"cell_type":"code","metadata":{"id":"uVYWS1EpsqVP"},"source":["df_grouped = df.groupby('height(cm)')\n","\n","df_grouped.get_group(160.0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xLVsX9YvuNjf"},"source":["**Aggregation functions with groupby\n","An aggregation function returns a single aggregated value for each group. Once the group by object is created, several aggregation operations can be performed on the grouped data as follows:-\n","\n","apply aggregation function sum with groupby\n","\n","df8.groupby('Gender').sum()\n","\n","alternative way to apply aggregation function sum\n","\n","df8.groupby('Gender').agg(np.sum)\n","\n","Another way to see the size of each group is by applying the size() function as follows:-\n","\n","df8_grouped = df8.groupby('Gender')\n","\n","print(df8_grouped.agg(np.size))**"]},{"cell_type":"code","metadata":{"id":"PIFiZpYRtkB3"},"source":["# It represents the total sum of each column by name\n","df.groupby('Name').agg(np.sum)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kv4GXZF7uIGD"},"source":["# It returns all the size of the data in a data frame\n","df.groupby('Weight(kg)').agg(np.size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-R5rCH6FwsFb"},"source":["**sum(): It returns the sum of the data frame\n","Syntax:\n","\n","dataframe[‘column].sum()**"]},{"cell_type":"markdown","metadata":{"id":"NEPGMcjdwzab"},"source":["**mean(): It returns the mean of the particular column in a data frame\n","Syntax:\n","\n","dataframe[‘column].mean()**"]},{"cell_type":"markdown","metadata":{"id":"7uV7CFXFw8fl"},"source":["**std(): It returns the standard deviation of that column.\n","Syntax:\n","\n","dataframe[‘column].std()\n","\n","**"]},{"cell_type":"markdown","metadata":{"id":"VpE0lztCxH00"},"source":["**var(): It returns the variance of that column\n","dataframe[‘column’].var()*"]},{"cell_type":"markdown","metadata":{"id":"ATfcRtjSxXAG"},"source":["**Applying multiple aggregation functions at once\n","\n","\n","With grouped series, you can also pass a list or dict of functions to do \n","\n","aggregation with, and generate dataframe as output as follows:-*"]},{"cell_type":"code","metadata":{"id":"_vanGxwHuzwL"},"source":["# it returns sum of the dataframe and mean of the particular column\n","df.groupby('Name')['height(cm)'].agg([np.sum, np.mean])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NihuNewh0Ak-"},"source":["*Filtration\n","Filtration filters the data on a defined criteria and returns the subset of data. \n","\n","\n","The filter() function is used to filter the data.**"]}]}